{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c482ee2-bf0f-4a24-af83-a8e10d93f5d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook follows the Medallion Architecture to process raw transaction item data from the Bronze layer into a structured, validated, and deduplicated Silver table. It focuses on maintaining the relationship between transactions and the individual items sold, ensuring data integrity for financial reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68d36143-d72e-4c5b-9663-32bf4b68e34f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Silver Layer: Transaction Items Transformation\n",
    "\n",
    "**Notebook Objective:** This notebook automates the cleaning and validation of transaction-level line items. \n",
    "\n",
    "It ensures that every item is linked to a valid transaction, handles price calculations, and implements a \"Quarantine\" pattern for records that fail business logic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f39b20d5-3e18-4153-b170-28a10743372e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Initial Data Profiling (Bronze Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4885d2bf-d97b-4765-883a-97d0c403d5c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We begin by investigating the raw data to identify missing identifiers or invalid financial figures that would corrupt downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72167088-0e5b-44de-a97a-b1af1433d146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. Check for Nulls in critical identifiers (Foreign Keys)\n",
    "SELECT * FROM `vstone-catalog`.bronze_schema.transactions_items_bronze \n",
    "WHERE cast(quantity as double) * cast(unit_price as double) != cast(subtotal as double);\n",
    "\n",
    "-- 2. Validate Price and Quantity\n",
    "-- Industry standard: Neither price nor quantity should be zero or negative\n",
    "SELECT count(*) FROM `vstone-catalog`.bronze_schema.transactions_items_bronze \n",
    "WHERE transaction_id IS NULL OR item_id IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921709a7-1aa2-4a3d-9f60-bfc28860feb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Configuration & Schema Initialization\n",
    "We define the Unity Catalog paths and ensure the destination environment is ready. Using backticks handles the hyphenated catalog name vstone-catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eac707f1-134a-4fd1-96ad-c3e8b62788cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Backticks are required because of the hyphen in the catalog name\n",
    "CATALOG = \"`vstone-catalog`\"\n",
    "SILVER_SCHEMA = \"silver_schema\"\n",
    "BRONZE_TABLE = f\"{CATALOG}.bronze_schema.transactions_items_bronze\"\n",
    "SILVER_TABLE = f\"{CATALOG}.{SILVER_SCHEMA}.silver_transaction_items\"\n",
    "QUARANTINE_TABLE = f\"{CATALOG}.{SILVER_SCHEMA}.quarantine_transaction_items\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b32a6a84-5ad9-4b46-a98b-76ab6b4215e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize schema\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SILVER_SCHEMA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b21317fd-8f75-4099-8fca-8780b1289070",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Data Ingestion & Header Standardization\n",
    "To maintain a clean data lake, we standardize all column headers to *snake_case.* This ensures that our Spark transformations and future SQL queries remain consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70b8fdd4-480d-4e44-991a-4a0d4ae7bc82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 3. LOAD & STANDARDIZE ---\n",
    "df_bronze = spark.read.table(BRONZE_TABLE)\n",
    "\n",
    "# Convert headers to lowercase and replace spaces with underscores)\n",
    "standardized_cols = [col.lower().replace(\" \", \"_\").strip() for col in df_bronze.columns]\n",
    "df_standardized = df_bronze.toDF(*standardized_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e23f4120-3abc-4486-b685-9db6398ff06f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##4. Quality Gates & Quarantine Logic\n",
    "Transaction items are the most granular level of financial data. \n",
    "\n",
    "We apply strict \"Quality Gates\" to catch errors like missing IDs or invalid pricing before they reach the Silver table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02b28c8f-68d2-4760-bd33-79e7d3da280d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. DATA TYPING & QUALITY GATES ---\n",
    "df_casted = df_standardized.select(\n",
    "    \"transaction_id\", \n",
    "    \"item_id\", \n",
    "    \"source\", \n",
    "    \"load_dt\",\n",
    "    F.col(\"quantity\").cast(\"double\").alias(\"quantity\"),\n",
    "    F.col(\"unit_price\").cast(\"double\").alias(\"unit_price\"),\n",
    "    F.col(\"subtotal\").cast(\"double\").alias(\"subtotal\"),\n",
    "    F.to_timestamp(F.col(\"created_at\")).alias(\"created_at\")\n",
    ")\n",
    "\n",
    "# --- 3. QUALITY GATES ---\n",
    "# Business Rules: \n",
    "# 1. Transaction and Item IDs must exist.\n",
    "# 2. Financials: Price and Quantity must be positive.\n",
    "math_valid = (F.round(F.col(\"quantity\") * F.col(\"unit_price\"), 2) == F.round(F.col(\"subtotal\"), 2))\n",
    "id_valid = (F.col(\"transaction_id\").isNotNull()) & (F.col(\"item_id\").isNotNull())\n",
    "qty_valid = (F.col(\"quantity\") > 0)\n",
    "\n",
    "valid_mask = math_valid & id_valid & qty_valid\n",
    "\n",
    "# Divert failed records to a Quarantine table for auditing\n",
    "df_quarantine = df_casted.filter(~valid_mask) \\\n",
    "    .withColumn(\"quarantine_reason\", \n",
    "        F.when(~id_valid, \"MISSING_MANDATORY_ID\")\n",
    "         .when(~qty_valid, \"ZERO_OR_NEGATIVE_QUANTITY\")\n",
    "         .otherwise(\"SUBTOTAL_MISMATCH\")) \\\n",
    "    .withColumn(\"quarantined_at\", F.current_timestamp())\n",
    "\n",
    "# Keep only the valid records\n",
    "df_clean = df_casted.filter(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40bad617-c0bf-4839-9e2e-c202ed535e5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5. Deduplication & Final Transformation\n",
    "We use a **Window function** to ensure we only keep the latest version of any given line item. We also cast data types to ensure high precision for financial double-entry bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e15d1c5-5786-4807-b231-0156e2075415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. DEDUPLICATION & NORMALIZATION ---\n",
    "# Logic: Partition by the unique combination of transaction and item\n",
    "window_spec = Window.partitionBy(\"transaction_id\", \"item_id\").orderBy(F.col(\"load_dt\").desc())\n",
    "\n",
    "df_silver_final = df_clean.withColumn(\"row_rank\", F.row_number().over(window_spec)) \\\n",
    "    .filter(\"row_rank == 1\").drop(\"row_rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc896ac4-453d-4288-9668-178c7f76992b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##6. Atomic Writes & Table Constraints\n",
    "The data is committed using the Delta Lake format, which supports ACID transactions. We apply hard constraints to the table to prevent future \"dirty\" data from being inserted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b50aca92-8a29-40bc-b9dd-d84d2fbc8924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 6. ATOMIC WRITES ---\n",
    "# Write Quarantine records\n",
    "df_quarantine.write.format(\"delta\").mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(QUARANTINE_TABLE)\n",
    "\n",
    "# Write Silver records\n",
    "df_silver_final.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(SILVER_TABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd3aa629-7db3-455c-96e6-384488ed3ddc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. APPLY CONSTRAINTS ---\n",
    "# Ensure primary keys are never null in the Silver layer\n",
    "\n",
    "spark.sql(f\"ALTER TABLE {SILVER_TABLE} ALTER COLUMN transaction_id SET NOT NULL\")\n",
    "spark.sql(f\"ALTER TABLE {SILVER_TABLE} ALTER COLUMN item_id SET NOT NULL\")\n",
    "\n",
    "try:\n",
    "    # Adding a check constraint for data integrity\n",
    "    spark.sql(f\"ALTER TABLE {SILVER_TABLE} ADD CONSTRAINT check_subtotal_pos CHECK (subtotal >= 0)\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Constraint might already exist or failed: {e}\")\n",
    "\n",
    "print(f\"Process complete. Silver table {SILVER_TABLE} updated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e371809-b3f1-4da8-908b-b347cb1ec4bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- View the audit trail\n",
    "DESCRIBE HISTORY `vstone-catalog`.silver_schema.silver_transaction_items;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb45be84-dbd6-44b2-9c0b-36d70849600b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Query the items as they were during the June 2024 promotion\n",
    "SELECT * FROM `vstone-catalog`.silver_schema.silver_transaction_items \n",
    "TIMESTAMP AS OF ' 2026-01-12 15:34:38';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e577016-980e-40e3-9162-ba39bf398a2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Industry Logics & Standards \n",
    "**1. Granular Integrity**\n",
    "In the retail industry, a single transaction has multiple \"line items\". By deduplicating on the combination of transaction_id and item_id, we ensure that our total sales quantity remains accurate.\n",
    "\n",
    "**2. The Quarantine Audit Trail**\n",
    "Rather than deleting records with price = 0, we move them to quarantine_transaction_items. This allows the finance team to investigate if these were \"test\" transactions or actual system bugs.\n",
    "\n",
    "**3. Delta Lake Constraints**\n",
    "By using ALTER TABLE ... ADD CONSTRAINT, we treat the Delta table like a traditional relational database. This \"Schema-on-Write\" approach is the gold standard for preventing data corruption in enterprise environments.\n",
    "\n",
    "**4. Idempotency**\n",
    "This notebook is designed to be idempotent. Because it uses .mode(\"overwrite\"), you can safely re-run the pipeline multiple times without creating duplicate records or causing data inflation."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5480252379363775,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Transactions Items Silver Table Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
