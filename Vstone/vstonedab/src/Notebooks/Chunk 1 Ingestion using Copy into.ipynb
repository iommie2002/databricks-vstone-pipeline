{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e83bb75b-e7b7-4d33-9f71-d98670d990e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Dynamic Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e07871b0-e558-4ce4-846d-73ca5f9ad256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "This section initializes the notebook parameters to allow for seamless deployment across different environments (Dev, Test, Prod).\n",
    "\n",
    "####Logic: \n",
    "\n",
    "The notebook uses dbutils.widgets to capture environment-specific variables like the catalog and schema names. \n",
    "\n",
    "####Why this code:\n",
    "\n",
    " Using widgets ensures the notebook is not hard-coded. By dynamically constructing the table name, the same logic can be used to target different Unity Catalog locations without manual code changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b0677f-2cd1-457f-9910-ced6f333255f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Capture Environment Variables from Spark Conf (set via DABs)\n",
    "# Logic: Retrieve the target location and source data path from job parameters\n",
    "dbutils.widgets.text(\"catalog_name\",\"\")\n",
    "dbutils.widgets.text(\"schema_name\",\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "409568b0-fddf-4960-8250-e61122638cf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"source_path\", \"/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5d46e4e-4319-4d0a-adb7-298c74e03702",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Get the values into Python variables\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "source_path=dbutils.widgets.get(\"source_path\")\n",
    "\n",
    "# Construct the full Delta table identifier for Unity Catalog\n",
    "table_name = f\"`{catalog_name}`.`{schema_name}`.`transactions_bronze`\"\n",
    "\n",
    "# 3. Create the table if it doesn't exist\n",
    "# Why: This prevents errors when running COPY INTO on a non-existent target\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54eea9c7-8e28-4fff-971f-507baca217f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Schema Seeding and COPY INTO Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d53ab597-f70b-4f27-bbd8-9d2409b9737c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This block handles the core ingestion logic, ensuring that the target table matches the source file structure while adding audit tracking.\n",
    "\n",
    "Logic: \n",
    "\n",
    "We first \"seed\" the table by creating it with the correct schema but zero rows. We then use the COPY INTO command to incrementally load only new data. \n",
    "\n",
    "Why this code: \n",
    "\n",
    "* COPY INTO: An idempotent operation that automatically skips files that have already been loaded, making it ideal for scheduled batch ingestion.\n",
    "\n",
    "* Metadata Tracking: By selecting _metadata.file_path, we provide a clear audit trail of which file contributed each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8707cc53-6141-4173-80c5-9b5a4c349485",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. SEED THE SCHEMA\n",
    "# Logic: Use read_files to infer the CSV schema and add placeholder audit columns\n",
    "# 'WHERE 1=0' ensures we define the structure without loading duplicate data initially\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} \n",
    "AS SELECT *, \n",
    "          cast(NULL as string) AS source_file, \n",
    "          current_timestamp() AS load_dt \n",
    "   FROM read_files('{source_path}', format => 'csv', header => true, inferSchema => true) \n",
    "   WHERE 1=0\n",
    "\"\"\")\n",
    "\n",
    "# 4. Execute Idempotent Ingestion\n",
    "# Logic: Copy data from the volume path while enriching it with file metadata\n",
    "spark.sql(f\"\"\"\n",
    "COPY INTO {table_name}\n",
    "FROM (\n",
    "  SELECT \n",
    "    *, \n",
    "    _metadata.file_path AS source_file, \n",
    "    current_timestamp() AS load_dt\n",
    "  FROM '{source_path}'\n",
    ")\n",
    "FILEFORMAT = CSV\n",
    "FORMAT_OPTIONS (\n",
    "    'header' = 'true',\n",
    "    'inferSchema' = 'true',\n",
    "    'mergeSchema' = 'true'\n",
    ")\n",
    "COPY_OPTIONS (\n",
    "    'mergeSchema' = 'true'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# 5. Display result\n",
    "display(spark.read.table(table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d41d2778-517e-459a-96f2-f97aa16ca814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Discovery & Audit Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20335ab6-1c9a-4eb0-91ae-da1138224917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The final section focuses on Data Governance by adding descriptions and properties to the table in Unity Catalog.\n",
    "\n",
    "####Logic: \n",
    "\n",
    "It applies table-level properties (quality, source) and column-level comments to improve discoverability. \n",
    "\n",
    "####Why this code: \n",
    "\n",
    "In an enterprise environment, metadata is as important as the data itself. These properties allow other data engineers and analysts to understand the data's lineage and purpose directly from the Unity Catalog UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9966d33b-244b-4437-9ace-5c7b79317c4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Add Discovery Metadata (Audit Properties)\n",
    "# Logic: Tag the table as 'bronze' and describe its origin\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {table_name} SET TBLPROPERTIES (\n",
    "  'quality' = 'bronze',\n",
    "  'source' = 'transactions_csv',\n",
    "  'description' = 'Enterprise transactions data ingested from volume chunk1'\n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2735b626-d9fd-4752-bef2-338664ac18e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Document audit columns for easy discovery in Unity Catalog\n",
    "spark.sql(\"ALTER TABLE \" + table_name + \" ALTER COLUMN load_dt COMMENT 'Data load timestamp'\")\n",
    "spark.sql(\"ALTER TABLE \" + table_name + \" ALTER COLUMN source_file COMMENT 'Source path of the ingested file'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Chunk 1 Ingestion using Copy into",
   "widgets": {
    "catalog_name": {
     "currentValue": "vstone-catalog",
     "nuid": "7ee27a22-1103-4e08-8c83-935587c75e2b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "bronze_schema",
     "nuid": "13657cd2-86fc-40c3-8d86-6812553170a7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "source_path": {
     "currentValue": "/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/",
     "nuid": "6a8a4fb0-2c24-4729-81ed-766807b43f26",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/",
      "label": null,
      "name": "source_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/",
      "label": null,
      "name": "source_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
