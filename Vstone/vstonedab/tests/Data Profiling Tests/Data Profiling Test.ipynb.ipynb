{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d19ea96e-b8ab-4540-bfcb-92c429ca3e9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook implements a Automated Testing Suite for the Data Profiling utility. It follows professional software engineering practices by separating core business logic from testing procedures, ensuring that the profiling metrics used in the production pipeline are accurate and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8fe7b16d-81dc-4e16-8a69-8bcf874051ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Core Profiling Logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "749ff265-1166-4b8e-9e0d-9231d519cd40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This section contains the refined calculate_profile_metrics function.\n",
    "\n",
    "####Logic: \n",
    "\n",
    "It programmatically assesses a DataFrame to calculate null distributions, total row counts, and duplicate entries based on Primary Key (PK) columns. \n",
    "\n",
    "####Why this code: \n",
    "\n",
    "By returning a DataFrame instead of just printing results, this function becomes \"testable.\" We can compare the output of this function against known expected results to verify its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ce8a1ca-9515-45d0-a712-4ae733a11ed8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, min, max, lit\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "\n",
    "def calculate_profile_metrics(df: DataFrame, table_name: str, pk_cols=None, date_col=None) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Pure logic for profiling. Returns the profile result as a DataFrame.\n",
    "    \"\"\"\n",
    "    total_rows = df.count()\n",
    "    \n",
    "    # 1. Null counts per column logic\n",
    "    null_counts = df.select([\n",
    "        spark_sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "        for c in df.columns\n",
    "    ])\n",
    "\n",
    "    # 2. Duplicate detection logic\n",
    "    duplicate_rows = 0\n",
    "    if pk_cols:\n",
    "        duplicate_rows = total_rows - df.select(pk_cols).distinct().count()\n",
    "\n",
    "    # 3. Date range analysis logic\n",
    "    min_date, max_date = None, None\n",
    "    if date_col:\n",
    "        dates = df.select(\n",
    "            min(col(date_col)).alias(\"min_date\"),\n",
    "            max(col(date_col)).alias(\"max_date\")\n",
    "        ).collect()[0]\n",
    "        min_date = dates[\"min_date\"]\n",
    "        max_date = dates[\"max_date\"]\n",
    "\n",
    "    # 4. Final summary construction: Cast dates to strings for schema consistency\n",
    "    return (\n",
    "        null_counts\n",
    "        .withColumn(\"table_name\", lit(table_name))\n",
    "        .withColumn(\"total_rows\", lit(total_rows))\n",
    "        .withColumn(\"duplicate_rows\", lit(duplicate_rows))\n",
    "        .withColumn(\"min_date\", lit(str(min_date))) # Cast to string for consistent comparison\n",
    "        .withColumn(\"max_date\", lit(str(max_date)))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d573bbe9-3c04-4972-9855-c8247d8543be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Unit and Integration Test Suite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0325c2f-e712-434f-940d-7528f2f209ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This section uses the unittest framework to validate the profiling logic and environment access.\n",
    "\n",
    "####Logic: \n",
    "    \n",
    "*Unit Tests: \n",
    "    \n",
    "    Create small, \"dummy\" DataFrames with known errors (like specific null counts) and assert that the function detects them correctly.\n",
    "\n",
    "*Integration Tests: \n",
    "    Verify that the Databricks environment can actually access the external Volumes where the raw data is stored. \n",
    "    \n",
    "####Why this code: \n",
    "\n",
    "Automated tests prevent \"regression\" (fixing one thing and breaking another). If the logic for calculating duplicates is ever changed, these tests will immediately flag any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f33bbbdd-8992-439e-9b25-394a43ae47e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "import io\n",
    "from unittest import TextTestRunner\n",
    "from pyspark.testing.utils import assertDataFrameEqual, assertSchemaEqual\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n",
    "\n",
    "class ProfilingLogicTest(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        # Use the existing SparkSession in the Databricks environment\n",
    "        cls.spark = spark\n",
    "\n",
    "    def test_null_count_logic(self):\n",
    "        \"\"\"Unit Test: Verify null counts are calculated accurately\"\"\"\n",
    "        # Create dummy data with 1 null in 'id' and 2 nulls in 'val'\n",
    "        data = [(\"1\", None), (None, \"A\"), (None, \"B\")]\n",
    "        df = self.spark.createDataFrame(data, [\"id\", \"val\"])\n",
    "        \n",
    "        profile_result = calculate_profile_metrics(df, \"test_table\")\n",
    "        \n",
    "        # Expect 2 nulls for 'id' and 1 for 'val'\n",
    "        actual_id_nulls = profile_result.select(\"id\").collect()[0][0]\n",
    "        actual_val_nulls = profile_result.select(\"val\").collect()[0][0]\n",
    "        \n",
    "        self.assertEqual(actual_id_nulls, 2)\n",
    "        self.assertEqual(actual_val_nulls, 1)\n",
    "\n",
    "    def test_duplicate_logic(self):\n",
    "        \"\"\"Unit Test: Verify duplicate row calculation\"\"\"\n",
    "        data = [(101, \"item1\"), (101, \"item1\"), (102, \"item2\")]\n",
    "        df = self.spark.createDataFrame(data, [\"pk_id\", \"name\"])\n",
    "        \n",
    "        profile_result = calculate_profile_metrics(df, \"dup_test\", pk_cols=[\"pk_id\"])\n",
    "        \n",
    "        actual_dups = profile_result.select(\"duplicate_rows\").collect()[0][0]\n",
    "        self.assertEqual(actual_dups, 1) # Total 3 rows - 2 distinct = 1 duplicate\n",
    "\n",
    "    def test_integration_volume_access(self):\n",
    "        \"\"\"Integration Test: Check access to Chunked Data Volumes\"\"\"\n",
    "        path = \"/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/\"\n",
    "        try:\n",
    "            dbutils.fs.ls(path)\n",
    "            accessible = True\n",
    "        except:\n",
    "            accessible = False\n",
    "        \n",
    "        self.assertTrue(accessible, f\"Path {path} must be accessible for profiling.\")\n",
    "\n",
    "# Initialize the suite\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(ProfilingLogicTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dece61d7-acbe-4563-ab8c-0dd799e20078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Quality Report Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f53b4bea-4bdc-4841-b6c4-b2b0c903253b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Logic: \n",
    "\n",
    "Executes the test suite and captures the output into a formatted report. \n",
    "\n",
    "####Why this code: \n",
    "\n",
    "In a production CI/CD (Continuous Integration/Continuous Deployment) pipeline, this report determines if the code is safe to deploy. A 100% success rate is required for the pipeline to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c87426c-f8a0-4e51-bbad-2b0eaecc1fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a stream to capture the report\n",
    "stream = io.StringIO()\n",
    "runner = TextTestRunner(stream=stream, verbosity=2)\n",
    "\n",
    "# Run tests\n",
    "result = runner.run(suite)\n",
    "\n",
    "# Print Final Report\n",
    "print(\"●●● DATA PROFILING QUALITY REPORT ●●●\")\n",
    "print(\"-\" * 40)\n",
    "print(stream.getvalue())\n",
    "print(\"-\" * 40)\n",
    "print(f\"TOTAL TESTS RUN: {result.testsRun}\")\n",
    "print(f\"SUCCESSES: {result.testsRun - len(result.failures) - len(result.errors)}\")\n",
    "print(f\"FAILURES: {len(result.failures)}\")\n",
    "print(f\"ERRORS: {len(result.errors)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if not result.wasSuccessful():\n",
    "    print(\"CRITICAL: Profiling logic validation failed. Use %debug to inspect.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d48eb780-158b-439f-ae57-1d947f95775d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####Report Summary\n",
    "\n",
    "*Total Tests Run: 3\n",
    "\n",
    "*Successes: 3\n",
    "\n",
    "*Failures: 0\n",
    "\n",
    "*Status:  OK"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Profiling Test.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
