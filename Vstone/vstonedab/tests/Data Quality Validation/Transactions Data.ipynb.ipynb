{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f51ed01-8a94-447a-ab42-95188a07b31e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "This notebook establishes a High-Fidelity Data Validation Framework for large-scale transaction data. \n",
    "\n",
    "It ensures that the ingestion process from raw CSV files to the Bronze layer maintains 100% data integrity through aggregate reconciliation and row-level fingerprinting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3da53696-aaae-439e-b549-679f1ac8c5c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Data Loading and Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d5b0432-c09a-4704-92ed-803d9003af00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The first phase involves loading the raw CSV transactions and simulating a row position to enable granular auditing.\n",
    "\n",
    "####Logic: \n",
    "\n",
    "The script reads raw CSV files from the Chunk 1 volume, captures the source file path, and uses a Window function with monotonically_increasing_id() to generate a gapless row number for every record. \n",
    "\n",
    "####Why this code:\n",
    "\n",
    " Standard CSV ingestion does not inherently track row positions. By creating a file_row_number, we can pinpoint the exact location of any data discrepancy found later in the audit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a16403e-eeaf-4c88-9940-8669b314b32d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# 1. Configuration: Define source volume path and target Bronze table\n",
    "raw_path = \"/Volumes/vstone-catalog/vstone_schema/chunked_data/chunk1/*.csv\"\n",
    "bronze_table_name = \"`vstone-catalog`.bronze_schema.transactions_bronze\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c34fb2-e85a-44ff-9ca9-d1be687a2176",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Load Raw Data with Metadata\n",
    "# Logic: capture the file path to distinguish records between monthly transaction files\n",
    "raw_df_initial = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(raw_path) \\\n",
    "    .select(\n",
    "        \"*\", \n",
    "        F.col(\"_metadata.file_path\").alias(\"source_file\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db87e420-9191-4eea-a282-ec389065547d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Simulate Row Index for Auditing\n",
    "# Logic: Use a Window spec to create a stable row count per file\n",
    "window_spec = Window.partitionBy(\"source_file\").orderBy(F.monotonically_increasing_id())\n",
    "raw_df = raw_df_initial.withColumn(\"file_row_number\", F.row_number().over(window_spec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e206d63-0a6b-43d5-8581-e3de927b2752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 4. Load Bronze Data\n",
    "bronze_df = spark.table(bronze_table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b1f6741-6dcd-4007-9d99-03d279ccf464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 5. Define MD5 Logic\n",
    "hash_cols = [\n",
    "    \"transaction_id\", \"store_id\", \"payment_method_id\", \"voucher_id\", \n",
    "    \"user_id\", \"original_amount\", \"discount_applied\", \"final_amount\", \"created_at\"\n",
    "]\n",
    "\n",
    "def add_row_hash(df, prefix=\"\"):\n",
    "    return df.withColumn(f\"{prefix}row_hash\", F.md5(F.concat_ws(\"||\", \n",
    "        *[F.coalesce(F.col(c).cast(\"string\"), F.lit(\"NULL\")) for c in hash_cols]\n",
    "    )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b92000e-aff7-4ea0-be98-bc44c1183273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Aggregate Validation (Step 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "418555a6-d4a0-4bec-bf2e-6e491c9044ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Before performing deep row-level checks, the script performs a high-level summary validation to ensure no records or financial values were lost.\n",
    "\n",
    "####Logic: \n",
    "\n",
    "It groups both the raw and Bronze data by source_file and calculates the total record count and the sum of the final_amount. \n",
    "\n",
    "####Why this code: \n",
    "\n",
    "This provides an immediate \"smoke test\". If the count_diff or amt_diff is non-zero, it indicates a critical failure in the ingestion pipeline that needs immediate attention before proceeding to more expensive row-level checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9028b7a-41c4-4714-baa2-72135fb006b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 6. High-Level Aggregate Validation\n",
    "# Logic: Compare record counts and total transaction amounts per file\n",
    "raw_agg = raw_df.groupBy(\"source_file\").agg(\n",
    "    F.count(\"*\").alias(\"raw_count\"),\n",
    "    F.sum(\"final_amount\").alias(\"raw_sum_amt\")\n",
    ")\n",
    "\n",
    "bronze_agg = bronze_df.groupBy(\"source_file\").agg(\n",
    "    F.count(\"*\").alias(\"bronze_count\"),\n",
    "    F.sum(\"final_amount\").alias(\"bronze_sum_amt\")\n",
    ")\n",
    "# Join aggregates to calculate differences\n",
    "comparison_df = raw_agg.join(bronze_agg, \"source_file\", \"outer\") \\\n",
    "    .withColumn(\"count_diff\", F.col(\"raw_count\") - F.col(\"bronze_count\")) \\\n",
    "    .withColumn(\"amt_diff\", F.round(F.col(\"raw_sum_amt\") - F.col(\"bronze_sum_amt\"), 2))\n",
    "\n",
    "print(\"Step 1: Aggregate Validation Results:\")\n",
    "comparison_df.select(\"source_file\", \"raw_count\", \"bronze_count\", \"count_diff\", \"amt_diff\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb86dd8d-d8a8-46be-9cb8-20d3ca234ff4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Row-Level Integrity Audit (Step 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c85aa560-5cb8-496e-868c-a63a7f0349e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The final validation gate uses MD5 hashing to ensure that every single field in every record was ingested correctly.\n",
    "\n",
    "####Logic:\n",
    "\n",
    " It generates an MD5 hash (fingerprint) of all business-critical columns (IDs, amounts, and timestamps). It then left-joins the raw data with the Bronze data on transaction_id and filters for any row where the hashes do not match.\n",
    " \n",
    "####Why this code: \n",
    "  \n",
    "  Financial data requires zero-tolerance for errors. This step detects \"silent\" data corruption, such as a decimal point shifting or a timestamp being truncated, which aggregate sums might miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f94fbbbb-857a-48c9-9fdf-048d4a04f90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 7. Row-Level Integrity Validation\n",
    "raw_final = add_row_hash(raw_df, \"raw_\")\n",
    "bronze_final = add_row_hash(bronze_df, \"bronze_\")\n",
    "\n",
    "mismatches = raw_final.select(\"transaction_id\", \"raw_row_hash\", \"source_file\", \"file_row_number\").join(\n",
    "    bronze_final.select(\"transaction_id\", \"bronze_hash\" if \"bronze_hash\" in bronze_df.columns else \"bronze_row_hash\"),\n",
    "    on=\"transaction_id\",\n",
    "    how=\"left\"\n",
    ").filter((F.col(\"raw_row_hash\") != F.col(\"bronze_row_hash\")) | (F.col(\"bronze_row_hash\").isNull()))\n",
    "\n",
    "# 8. Report\n",
    "mismatch_count = mismatches.count()\n",
    "if mismatch_count == 0:\n",
    "    print(f\"✅ SUCCESS: All records match the Bronze table exactly.\")\n",
    "else:\n",
    "    print(f\"❌ CRITICAL: Found {mismatch_count} discrepancies.\")\n",
    "    mismatches.select(\"file_row_number\", \"transaction_id\", \"source_file\").show(20)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Transactions Data.ipynb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
