{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1a7aeb6-d4c6-4441-b687-616e318bea98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook implements the Medallion Architecture to process raw user data from the Bronze layer into a high-integrity, analytics-ready Silver table. The logic focuses on identifying PII (Personally Identifiable Information) patterns, standardizing contact information, and enforcing data quality through a quarantine mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8261d389-acf5-4547-9488-c7c6e7ea724e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Silver Layer: Users Transformation\n",
    "**Notebook Objective:** This notebook implements the cleaning and validation of user account data. \n",
    "\n",
    "It ensures that every user has a valid identifier and email format, deduplicates account records to find the latest \"state\" of a user, and enforces strict storage-level constraints for data governance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95188bcb-2fa3-42c1-9c39-30fefa7203aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Initial Data Profiling (Bronze Layer)\n",
    "We begin by auditing the raw Bronze data to identify missing critical identifiers and evaluate the quality of email entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d75ac658-2a63-475f-82f8-d529c2bbd00a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1. Check for missing primary identifiers\n",
    "SELECT count(*) FROM `vstone-catalog`.bronze_schema.users_bronze WHERE _rescued_data IS NOT NULL;\n",
    "\n",
    "-- 2. Check for date format inconsistencies\n",
    "SELECT birthdate, count(*) \n",
    "FROM `vstone-catalog`.bronze_schema.users_bronze \n",
    "GROUP BY birthdate ORDER BY count(*) DESC LIMIT 5;\n",
    "\n",
    "-- 3. Check for Null IDs\n",
    "SELECT count(*) FROM `vstone-catalog`.bronze_schema.users_bronze WHERE user_id IS NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dc05eda-a39e-4fc1-b685-85a1af42342a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Configuration & Environment Setup\n",
    "We define the paths using Unity Catalog's three-tier namespace and initialize the destination schema to ensure the code is self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe3f14ba-53a9-4733-a50f-3a30c17b5e4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Using backticks to escape hyphens in the catalog name\n",
    "CATALOG = \"`vstone-catalog`\"\n",
    "SILVER_SCHEMA = \"silver_schema\"\n",
    "BRONZE_TABLE = f\"{CATALOG}.bronze_schema.users_bronze\"\n",
    "SILVER_TABLE = f\"{CATALOG}.{SILVER_SCHEMA}.silver_users\"\n",
    "QUARANTINE_TABLE = f\"{CATALOG}.{SILVER_SCHEMA}.quarantine_users\"\n",
    "\n",
    "# Bootstrap: Ensure the Silver schema exists before processing\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG}.{SILVER_SCHEMA}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14917993-96f2-4a65-91c9-9d2edbf2c321",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Ingestion & Header Standardization\n",
    "To ensure cross-table compatibility, we normalize all column headers into snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72842f39-320f-4cc9-b5aa-8ee7ec8a5dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. PANDAS UDF FOR STANDARDIZATION ---\n",
    "@pandas_udf(StringType())\n",
    "def standardize_gender_udf(gender_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Standardizes gender strings (e.g., 'M', 'male', 'MALE' -> 'Male').\"\"\"\n",
    "    mapping = {'m': 'Male', 'f': 'Female', 'n': 'Non-binary', 'o': 'Other'}\n",
    "    # Clean string and take first character for mapping\n",
    "    clean_series = gender_series.str.lower().str.strip().str[0]\n",
    "    return clean_series.map(mapping).fillna('Unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9074b205-f5cc-4fe5-88f2-68045e5aa2eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 2. LOAD & STANDARDIZE HEADERS ---\n",
    "df_bronze = spark.read.table(BRONZE_TABLE)\n",
    "\n",
    "# Standardize column names to lowercase and replace spaces with underscores\n",
    "standardized_cols = [col.lower().replace(\" \", \"_\").strip() for col in df_bronze.columns]\n",
    "df_standardized = df_bronze.toDF(*standardized_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dcd538b-c20f-4d21-9638-a6055afb747f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##4. Quality Gates & Quarantine Pattern\n",
    "\n",
    "We implement a \"Quarantine\" logic to separate malformed records. In an industry setting, this prevents the loss of data while ensuring that only valid information reaches the Silver table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "185d8305-866c-4310-8a59-8adb23fbb8bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. QUALITY GATES ---\n",
    "# Business Rules: \n",
    "# 1. user_id must be present.\n",
    "\n",
    "id_valid = F.col(\"user_id\").isNotNull()\n",
    "reg_valid = F.to_timestamp(F.col(\"registered_at\")).isNotNull()\n",
    "\n",
    "valid_mask = id_valid & reg_valid\n",
    "\n",
    "# Redirect invalid records to Quarantine table with a reason code\n",
    "df_quarantine = df_standardized.filter(~valid_mask) \\\n",
    "    .withColumn(\"quarantine_reason\", \n",
    "        F.when(~id_valid, \"MISSING_USER_ID\")\n",
    "         .otherwise(\"INVALID_REGISTRATION_DATE\")) \\\n",
    "    .withColumn(\"quarantined_at\", F.current_timestamp())\n",
    "    \n",
    "# Proceed with clean data\n",
    "df_clean = df_standardized.filter(valid_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3edede8-e0da-49f1-8918-955eba3f518a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5. Deduplication & Transformation\n",
    "Since user profiles can change over time (e.g., name changes or email updates), we use a Window function to identify the most recent record for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c383944-9d14-4b9a-a7eb-bfcd72d8b758",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 4. DEDUPLICATION & NORMALIZATION ---\n",
    "# Logic: Partition by user_id and keep the record with the latest load_dt\n",
    "window_spec = Window.partitionBy(\"user_id\").orderBy(F.col(\"load_dt\").desc())\n",
    "\n",
    "# Check if _rescued_data exists before dropping to prevent errors\n",
    "drop_cols = [\"row_rank\"]\n",
    "if \"_rescued_data\" in df_clean.columns:\n",
    "    drop_cols.append(\"_rescued_data\")\n",
    "\n",
    "df_silver_final = df_clean.withColumn(\"row_rank\", F.row_number().over(window_spec)) \\\n",
    "    .filter(\"row_rank == 1\") \\\n",
    "    .drop(*drop_cols) \\\n",
    "    .withColumn(\"gender\", standardize_gender_udf(F.col(\"gender\"))) \\\n",
    "    .withColumn(\"birthdate\", F.to_date(F.col(\"birthdate\"))) \\\n",
    "    .withColumn(\"registered_at\", F.to_timestamp(F.col(\"registered_at\"))) \\\n",
    "    .withColumn(\"load_dt\", F.to_timestamp(F.col(\"load_dt\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35f68c87-ba65-4d78-8d5b-71ad9248d43a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##6. Atomic Delta Writes & Table Constraints\n",
    "We commit the data using the Delta Lake format and apply hard constraints to the table. This ensures that any future data ingestion that violates these rules will be blocked at the storage level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "012465cf-d6fd-4768-a68e-0f956bba994a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 5. ATOMIC WRITES ---\n",
    "# Write to Quarantine (Append mode) and Silver (Overwrite mode)\n",
    "df_quarantine.write.format(\"delta\").mode(\"append\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(QUARANTINE_TABLE)\n",
    "\n",
    "# Write Silver table (Overwrite for full refresh)\n",
    "df_silver_final.write.format(\"delta\").mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(SILVER_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aeb41132-c122-4475-9fd9-68556b2981e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- 6. APPLY DELTA CONSTRAINTS ---\n",
    "# Enforce that user_id can never be null in the Silver layer\n",
    "spark.sql(f\"ALTER TABLE {SILVER_TABLE} ALTER COLUMN user_id SET NOT NULL\")\n",
    "\n",
    "print(f\"Silver table {SILVER_TABLE} updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72ad205e-c6f7-4a61-97e1-5a8729041e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Check when a specific user record was updated\n",
    "DESCRIBE HISTORY `vstone-catalog`.silver_schema.silver_users;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bff20162-b750-4e89-b456-b86282aba475",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Query a specific version to see a user's previous 'gender' or 'birthdate' entry\n",
    "SELECT * FROM `vstone-catalog`.silver_schema.silver_users VERSION AS OF 1 WHERE user_id = 'usr_123';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "414b7b29-e67c-41d7-ad78-697dbecaa3a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Industry Logics & Standards \n",
    "The Single Source of Truth: By deduplicating based on load_dt, the Silver table acts as the \"current state\" of the user database, essential for CRM and personalized marketing.\n",
    "\n",
    "**Idempotency:** The use of .mode(\"overwrite\") ensures that if the notebook is re-run, it replaces the Silver data with the exact same cleaned results, preventing data duplication.\n",
    "\n",
    "**Data Quality Governance:** The Quarantine Pattern provides an audit trail. Instead of data simply \"disappearing\" because it failed a check, it is stored in quarantine_users so data engineers can fix source-system issues.\n",
    "\n",
    "**Storage-Level Firewalls:** Using ALTER TABLE ... SET NOT NULL is a proactive security measure. It ensures that no matter what pipeline or user writes to the Silver table in the future, the integrity of the primary key remains intact."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Users Silver Table Creation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
